---
title: "Peekbank import script for Nordmeyer & Frank (2014), JML"
output: html_document
---

Packages. 

```{r setup, message = FALSE, warning = FALSE}
library(here)
library(XML)
library(reader)
library(fs)
library(feather)
library(tidyverse)
library(peekds)
library(osfr)
library(kableExtra)
library(knitr)
library(janitor)
library(glue)
```

Then, set up general parameters and file paths. In this step, we will also download the raw files if they are not on our local machine.

Note that 5_1 and 5_2 are designations for Experiment 1 (the two orders). 5_3 and 5_4 are Experiment 2. 
This information will be saved as conditions in table trial_types table.

```{r parameters, message = FALSE, warning = FALSE}
dataset_name <- "nordmeyer_negtracker_2014"
project_root <- here::here()
dataset_id <- 0
file_ext = '.txt'
OSF_ADDRESS <- "pr6wu"

# check raw data directory
raw_data_path <- fs::path(project_root, "data", dataset_name, "raw_data")
full_dataset_path <- fs::path(raw_data_path, "full_dataset")
exp_info_path <- fs::path(raw_data_path, "experiment_info")
aoi_path <- fs::path(raw_data_path, "test_aois")
source(fs::path(project_root, "data", dataset_name, "import_scripts", "import_helpers.R"))

# only download raw data if it's not on your local machine
if(length(list.files(full_dataset_path)) == 0 & length(list.files(exp_info_path)) == 0) {
  # check if raw_data_path exists to avoid generating an error in using get_raw_data
  if (!file.exists(raw_data_path)){
    dir.create(raw_data_path)
  }
  get_raw_data(lab_dataset_id = dataset_name, path = raw_data_path, osf_address = OSF_ADDRESS)
}

# trial_file_name <- "reflook_v3_tests.csv"
participant_file_name <- "negtracker_master_list.csv"
participant_file_path <- fs::path(exp_info_path, participant_file_name)
# trial_file_path <- fs::path(exp_info_path, trial_file_name)
```

Let's create the first `datasets` table. This table just has some information about the dataset, which we'll just generate manually. 

```{r datasets, message = FALSE, warning = FALSE}
df_dataset <- tibble(
  dataset_id = dataset_id,
  lab_dataset_id = dataset_name,
  dataset_name = dataset_name,
  cite = "Nordmeyer, A. E., Frank, M. C. (2014). The role of context in young children's comprehension of negation. Journal of Memory and Language, 77, 25â€“39.",
  shortcite = "Nordmeyer & Frank (2014)"
)

df_dataset %>% 
  kable() %>% kable_styling()
```

<!-- Next, let's read in the area of interest (AOI) information.  -->
<!-- We're using a custom helper function to do this, and you may need to write some custom code to load in your AOI information. If your AOI dimensions are in columns in your eyetracking data file rather than in a separate file, skip this step and get the AOI information after reading in the eyetracking data by grabbing distinct AOIs from that table. -->

<!-- We'll create two tables: one that has the distinct sets of AOI regions and their dimensions, indexed with unique IDs, and one that connects trial types to these IDs. Only the `aoi_region_sets` will eventually be a table that is written and uploaded to peekbank; the correspondence between trial types and AOI IDs will later be used in the `trial_types` table. There's only one set of AOI regions in this experiment, so all stimuli are linked to AOI region ID `0`. -->

<!-- ```{r aoi, message = FALSE, warning = FALSE} -->
<!-- aoi_info_all <- process_smi_aoi(trial_file_name, exp_info_path)  -->

<!-- # clean up aoi_region_sets -->
<!-- aoi_region_sets <- aoi_info_all %>% -->
<!--   dplyr::select(-stimulus_name) %>% -->
<!--   distinct() %>% -->
<!--   mutate(aoi_region_set_id = seq(0,length(l_x_min)-1)) -->

<!-- aoi_region_sets %>%  -->
<!--   kable() %>% kable_styling() -->

<!-- # create table of aoi region ids and trial types -->
<!-- # this information will later be added to the  -->
<!-- aoi_ids <- aoi_info_all %>% -->
<!--   left_join(aoi_region_sets, by = c("l_x_min", "l_x_max", "l_y_min", "l_y_max", "r_x_min", "r_x_max", "r_y_min", "r_y_max")) %>% -->
<!--   distinct(stimulus_name, aoi_region_set_id)   -->

<!-- aoi_ids %>%  -->
<!--   slice(1:5) %>% -->
<!--   kable() %>% kable_styling() -->
<!-- ``` -->

<!-- Next, let's create the stimulus table. Stimuli are distinct image-label pairings in the experiment. On each trial, there are two stimuli (e.g., *book* and *frog*). Here, we're reading in the list of stimuli from a file of stimulus names that was already created in the raw data. Alternatively, you could get the stimulus list by reading in the file of eyetracking data and taking distinct items in the stimulus column. -->

<!-- ```{r stimuli, message = FALSE, warning = FALSE} -->
<!-- ##create stimuli data -->
<!-- stimuli_data <- process_smi_stimuli(trial_file_path) %>% -->
<!--   mutate(stimulus_id = seq(0,length(stimulus_label)-1), -->
<!--          original_stimulus_label = stimulus_label) %>% -->
<!--   rename(english_stimulus_label = stimulus_label) -->

<!-- stimuli_data %>%  -->
<!--   slice(1:5) %>% -->
<!--   kable() %>% kable_styling() -->
<!-- ``` -->

This is the code from `https://github.com/anordmey/Negtracker/blob/master/materials/analysis/negtracker_makeLongData.R`

Let's create df_administrations and df_subjects from participant info file.

```{r}
#Load in demographics
demographics <- read_csv(participant_file_path) |>
  filter(exclude == 0, 
         (`study version` %in% c("5_1","5_2","5_3","5_4")), 
         agegroup %in% c("2","3","4")) |>
  mutate(experiment = ifelse(`study version` %in% c("5_1","5_2"), 1, 2))

demographics |>
  group_by(experiment, agegroup) |>
  count() |>
  kable()

df_subjects <- demographics |>
  mutate(native_language = "eng") |>
  mutate(lab_subject_id = subid) |>
  mutate(sex = gender) |>
  mutate(subject_id = seq(0,length(subid)-1)) |>
  select(subject_id, sex, native_language, lab_subject_id)
  
```

This filtering gets us a list that reproduces the original numbers from the paper for each experiment. (Note this is kids included **before** trial-level exclusions). 

```{r}
# this code modified from the negtracker repository
# https://github.com/anordmey/Negtracker/tree/master/materials/analysis

x.max <- 1680 #this is the resolution
all.data <- data.frame()
to.n <- function(x) {as.numeric(as.character(x))}

#get list of files for data analysis
files <- 0
for (i in 1:length(demographics$subid)) {
  files[i] <- paste("negtracker",demographics$`study version`[i],"_",demographics$subid[i],"-eye_data Samples.txt", sep="")
}

#Make longform dataframe
for (f in 1:length(files)) {
  print(files[f])
  
  ############ DATA CLEANING ###########
  #Load in data file (skip removes header rows)
  idf.data <- read.table(paste0(full_dataset_path,"/", files[f]),
                         sep="\t",header=TRUE,fill=TRUE, comment.char="", skip=40)
  names(idf.data) <- c("Time","Type","Trial","L.POR.X..px.","L.POR.Y..px.","R.POR.X..px.","R.POR.Y..px.","Frame","Aux1")
  
  ### split data into messages and data
  ###First get data:
  data <- subset(idf.data,idf.data$Type=="SMP")
  
  ## average monocular gaze data to get binocular vision
  data$"L.POR.X..px." <- to.n(data$"L.POR.X..px.")
  data$"R.POR.X..px." <- to.n(data$"R.POR.X..px.")
  data$"L.POR.Y..px." <- to.n(data$"L.POR.Y..px.")
  data$"R.POR.Y..px." <- to.n(data$"R.POR.Y..px.")
  data$x.pos <- rowMeans(data[,c("L.POR.X..px.","R.POR.X..px.")])
  data$y.pos <- rowMeans(data[,c("L.POR.Y..px.","R.POR.Y..px.")])
  
  #clean up data
  data <- data[,c("Time","x.pos")]
  
  ###Now get messages: 
  msgs <- subset(idf.data,idf.data$Type=="MSG")
  msgs <- msgs[,c("Time","L.POR.X..px.")]
  names(msgs) <- c("Time","Message")
  msgs$Message <- as.character(msgs$Message)
  msgs$trial <- gsub("# Message: ", "",msgs$Message)
  
  ## merge trial information back into data frame
  data$trial <- sapply(data$Time,function(x) {set <- msgs$trial[msgs$Time < x]
  set[length(set)]})
  
  ## drop the times before the first video
  data <- data[grep(".",data$trial,fixed=TRUE),]
  data$trial <- unlist(data$trial)
  
  ## set up some timing variables
  #Mark trial change
  data$stim.change <- c(diff(as.numeric(as.factor(data$trial))) != 0,0)
  #count time from start of trial to end of experiment
  data$t <- (data$Time - data$Time[1])/(1000000)
  
  #count time from beginning to end of each trial
  data$dt <- c(diff(data$t),0)
  t <- 0
  data$t.stim <- mapply(function (x,y) { 
    if(x==T) {
      t <<- 0
      return(t)
    } else {
      t <<- t + y
      return(t)
    }},data$stim.change,data$dt)
  
  #Find test trials only (no fillers, practice trials, etc.)
  data <- data[grepl("item",data$trial),]
  data <- data[!grepl("practice",data$trial),]
  data <- data[!grepl("pos",data$trial),] #feedback slide
  data <- data[!grepl("neg",data$trial),] #feedback slide
  
  #get trial number
  data$trial.num <- cumsum(data$stim.change)+1
  
  #Get info out of file name
  splits <- strsplit(files[f],"_")[[1]]
  data$subid <- paste(splits[3],str_sub(splits[4],start=1,end=2),sep="_")
  
  #get condition.  "nothing" is Exp 1 and "something" is Exp 2
  data$condition <- 
    if (splits[2] == "1" | splits[2] == "2") {
      data$condition <- "nothing"
    } else if (splits[2] == "3" | splits[2] == "4"){ 		
      data$condition <- "something"
    }
  
  #Label item
  data$item <- as.character(sapply(data$trial,function(x) {strsplit(x,"_")[[1]][1]}))
  
  ##Merge onsets: this gives onsets of multiple parts of the trial sentence
  if (splits[2] == "1" | splits[2] == "3") {
    onsets <- read.csv(paste0(exp_info_path, "/timing_exp1.csv"))
  } else if (splits[2] == "2" | splits[2] == "4"){ 		
    onsets <- read.csv(paste0(exp_info_path, "/timing_exp2.csv"))
  }
  
  data <- merge(data,onsets,sort=FALSE,all.x=T)
  
  #t.target centers timing around onset of the target noun
  data$t.target <- data$t.stim - data$noun_onset
  
  #Use sentence type and item side to determine what side the target character was on
  data$left.side <- grepl("itemL",data$trial) #what side of the screen was the character with target items on?
  data$target.side <- mapply(function (x,y) { 
    if(x=="positive" & y==T) {
      t <<- "left"
      return(t)
    } else if (x=="positive" & y==F) {
      t <<- "right"
      return(t)
    } else if (x=="negative" & y==T) {
      t <<- "right"
      return(t)
    } else if (x=="negative" & y==F) {
      t <<- "left"
      return(t)
    }},data$type,data$left.side)
  
  ##clean up x position data
  data$x.pos[data$x.pos < 1 | data$x.pos > x.max] <- NA
  
  #Identify whether gaze was on target side 
  data$target.looks <- data$x.pos
  data$target.looks[data$target.side == "left"] <- x.max - data$target.looks[data$target.side == "left"]
  data$on.target <- data$target.looks > (x.max / 2) + 200 
  
  ## clean up data frame
  data <- data[,c("subid","condition","item","trial.num","trial","type","t.stim","t.target","x.pos","on.target","target.side","noun_onset")]
  
  all.data <- bind_rows(all.data,data)
}

all.data$condition <- as.factor(all.data$condition)
```

Some cleanup for subsequent processing. 

```{r}
all_data <- all.data |>
  left_join(demographics |>
              select(subid, `experiment`, `study version`, age, gender)) |>
  as_tibble() |>
  clean_names()
  
```

Now we can back out the Peekbank data. 

Since they didn't use AOIs anyway, we're going to pretend we have no AOIs. 

Next, let's create the stimulus table.

<!-- Stimuli are distinct image-label pairings in the experiment. On each trial, there are two stimuli (e.g., *book* and *frog*). Here, we're reading in the list of stimuli from a file of stimulus names that was already created in the raw data. Alternatively, you could get the stimulus list by reading in the file of eyetracking data and taking distinct items in the stimulus column. --> -->

Note that we need to load in distractor stimuli AND we need to add a "nothing" stimulus. 

```{r stimuli, message = FALSE, warning = FALSE}
expt_2_distractors <- read_csv(paste0(exp_info_path, "/experiment_2_distractors.csv")) |>
  mutate(target = sapply(strsplit(trial, '_'), `[`, 1)) |>
  mutate(side = case_when(substrRight(trial, 4, 4) == "L"))

tmp <- sapply(strsplit(expt_2_distractors$trial, '_'), `[`, 1) 

items <- unique(all_data$item)
singulars <- c("carrot", "cookie", "cake","spoon","bucket","organge","lollipop","car",
               "kite","banana","fish","balloon","apple","ball","ice cream","flower")

##create stimuli data
stimuli_data <- data_frame(original_stimulus_label = items,
                           english_stimulus_label =  singulars,
                           stimulus_novelty = "familiar", 
                           stimulus_image_path = NA, 
                           image_description = paste0("boy with ",  unique(all_data$item)),
                           image_description_source = "Peekbank discretion",
                           lab_stimulus_id = NA, 
                           datset_id = 0) |>
  mutate(stimulus_id = 1:n() - 1)

stimuli_data %>%
  slice(1:5) %>%
  kable() %>% kable_styling()
```


Now we'll create the `trials` and `trial_types` tables. 

<!-- The `trials` table is created by grabbing all distinct trial orders from the timepoint data. This table is distinct from the `trial_types` table and specifies the different trial orderings subjects can see. If your experiment has only one trial ordering, this table will have a row for each `trial_order` (0, 1, 2, ...) in the experiment, each associated with a `trial_type_id` linked to the `trial_types` table. If there are multiple trial orderings in your experiment, this table will encode each correspondence between trial types and positions in the trial order that was seen by a subject.  -->

The `trial_types` table specifies different combinations of target items, distractor items, target sides (left or right), AOI region sets and so on--essentially, all the trial-level parameters.

```{r trials, message = FALSE, warning = FALSE}

  # process_smi_trial_info(trial_file_path) %>%
  # left_join(stimuli_data %>% 
  #             select(stimulus_id, english_stimulus_label),
  #           by=c("distractor_label" = "english_stimulus_label")) %>%
  # rename(distractor_id = stimulus_id) %>%
  # left_join(stimuli_data %>% select(stimulus_id, english_stimulus_label),
  #           by=c("target_label" = "english_stimulus_label")) %>%
  # rename(target_id = stimulus_id) %>%
  # left_join(aoi_ids, by="stimulus_name") %>%
  # mutate(condition = object_type) %>%
  # mutate(full_phrase = paste0("Can you find the ", target_label, "?")) %>%
  # dplyr::select(trial_type_id, full_phrase, full_phrase_language, 
  #               point_of_disambiguation, target_side, 
  #               lab_trial_id, aoi_region_set_id, dataset_id, 
  #               distractor_id, target_id, condition)

# create trials data and match with stimulus id and aoi_region_set_id
# trial_types_data <- 
all_data |>
  select(experiment, condition, type, item, study_version, target_side, 
         noun_onset) |>
  distinct() |>
  mutate(trial_type_id = 1:n(),
         full_phrase = ifelse(type == "positive", 
                              glue("Look at the boy who has {item}"), 
                              glue("Look at the boy who has no {item}")),
         full_phrase_language = "eng",
        lab_trial_id = glue("{experiment} {study_version} {condition} {item}"),
        aoi_region_set_id = NA,
        dataset_id = 1, 
        ) |>
  rename(point_of_disambiguation = noun_onset)    
  
# trial_type_id, full_phrase, full_phrase_language, 
  #               point_of_disambiguation, target_side, 
  #               lab_trial_id, aoi_region_set_id, dataset_id, 
  #               distractor_id, target_id, condition
  
  
  select(-lab_trial_id, -dataset_id) %>%
  slice(1:5) %>%
  kable() %>% kable_styling()
```

```
# create trials data
trials_data <- all_data %>%
  
  distinct(trial_id, trial_order, trial_type_id)

trials_data %>% 
  slice(1:5) %>%
  kable() %>% kable_styling()


```



```{r timepoint-data, message = FALSE, warning = FALSE}
# get all file paths in the directory with raw eyetracking data
all_files <- list.files(path = full_dataset_path, 
                        pattern = paste0('*',file_ext),
                        all.files = FALSE)
# create file paths
all_file_paths <- fs::path(full_dataset_path, all_files)

# create eyetracking timepoint data
timepoint_data <- lapply(all_file_paths, process_smi_eyetracking_file)%>%
  bind_rows() %>%
  mutate(xy_timepoint_id = seq(0,length(lab_subject_id)-1)) %>%
  mutate(subject_id = as.numeric(factor(lab_subject_id, levels=unique(lab_subject_id)))-1) %>%
  mutate(trial_order = trial_type_id + 1,
         trial_id = trial_type_id)

timepoint_data %>% 
  slice(1:5) %>%
  kable() %>% kable_styling()
```

Next, let's make the `subjects` table. In this dataset, we have subject information in a separate file that's linked to subject IDs in the timepoints table. We want to make sure to only include subjects we have data for in the `subjects` table, so we'll get distinct subject IDs from the timepoints data and then join in other subject information from the separate subjects info file.

We'll also create the `administrations` table. This is a table with information for each administration, or run of the experiment. It includes information about the eyetracker used and the size of the monitor. If your experiment is longitudinal, there may be multiple administrations per subject. 

```{r subjects, message = FALSE, warning = FALSE}
## extract unique subjects ids from eyetracking data 
participant_id_table <- timepoint_data %>%
  distinct(lab_subject_id, subject_id)

#create subject data
subjects_data <- process_subjects_info(participant_file_path) %>%
  left_join(participant_id_table, by="lab_subject_id") %>%
  filter(!is.na(subject_id)) %>%
  mutate(native_language = "eng") %>%
  dplyr::select(subject_id, sex, lab_subject_id, native_language)

subjects_data %>% 
  slice(1:5) %>%
  kable() %>% kable_styling()

# get monitor size and sample rate
monitor_xy <- extract_smi_info(all_file_paths[1], monitor_size)
sample_rate <- extract_smi_info(all_file_paths[1], sample_rate)

# get maximum x-y coordinates on screen
screen_xy <- str_split(monitor_xy, "x") %>%
  unlist()
x_max <- as.numeric(as.character(screen_xy[1]))
y_max <- as.numeric(as.character(screen_xy[2]))
```

We also want to get administrations information. Note that you will need to look at your data and determine the units in which age is recorded, and adjust the processing script accordingly. If the ages in your dataset were in days or years (to decimal precision), you'd need to convert to months, by dividing by 365.25 or multiplying by 12 respectively. If the ages in your dataset are in whole number years, convert to midway through that year in months, e.g., 2 years would become 2*12 + 6 = 30 months. This is so that we don't systematically underestimate the age of children whose ages are recorded in whole years. If this is true of your dataset, `lab_age_units` should be coded as "whole years".

```{r admins}
# create administration info 
administration.data <- process_subjects_info(participant_file_path) %>%
  dplyr::select(lab_subject_id, age, lab_age, lab_age_units) %>%
  mutate(dataset_id = dataset_id, 
         tracker = "SMI", 
         monitor_size_x = x_max,
         monitor_size_y = y_max,
         sample_rate = sample_rate, 
         coding_method = "eyetracking")

# use subjects table and join back in administration info to create final
# administration table
administration_data <- participant_id_table %>%
  left_join(administration.data, by = "lab_subject_id") %>%
  dplyr::select(dataset_id, subject_id, age, lab_age, lab_age_units, 
                monitor_size_x, monitor_size_y, sample_rate, tracker, coding_method) %>%
  mutate(administration_id = seq(0,length(subject_id)-1)) 

administration_data %>% 
  select(-lab_age) %>%
  slice(1:5) %>%
  kable() %>% kable_styling()
```


The timepoint eyetracking data needs to go through some processing to become two tables: `xy_timepoints`, which encodes the x and y coordinates of the subject's eye movements at each time point, and `aoi_timepoints`, which encodes the AOI the subject is looking at (target, distractor, other, or missing) at each timepoint.  

Right now, our data has time (in milliseconds) recorded starting at zero at the beginning of the experiment and counting upward for the entire length of the experiment. We'll use some `peekds` functions to make this time consistent with the Peekbank schema. First, we'll need to `rezero_times()`: make `t` restart at zero at the beginning of each trial. Next, we `normalize_times()`: within each trial, center time at the `point_of_disambiguation` (the onset of the target word). After this step, each trial will start at a negative timepoint and will iterate up to the `point_of_disambiguation`, which will be at `t` = 0; looking timepoints after the `point_of_disambiguation` will be positive. Finally, we will `resample_times()` so that the looking data are sampled at a consistent rate across all of Peekbank. If your data are already zeroed, you can skip that step; if they are already centered at the target onset, you only need to resample.  

```{r }
# create xy data by merging in administration info and trial type info
xy_merged_data <- timepoint_data %>%
  mutate(dataset_id = dataset_id) %>%
  left_join(administration_data %>% select(subject_id, administration_id), by = "subject_id")%>%
  left_join(trial_types_data %>% select(trial_type_id, 
                                        aoi_region_set_id, 
                                        target_side,
                                        point_of_disambiguation), by = "trial_type_id") %>%
  left_join(aoi_region_sets, by = "aoi_region_set_id") 

# select relevant columns for xy_timepoints
# rezero, normalize and resample times
xy_data <- xy_merged_data %>%
  dplyr::select(xy_timepoint_id,x,y,t, administration_id, trial_id, point_of_disambiguation) %>%
  peekds::rezero_times(.) %>%
  peekds::normalize_times(.) %>%
  peekds::resample_times(., table_type = "xy_timepoints") %>%
  select(xy_timepoint_id, x, y, t_norm, administration_id, trial_id)

xy_data %>%
  slice(1:5) %>%
  kable() %>% kable_styling()

# create aoi data using peekds function add_aois()
# rezero, normalize and resample times
aoi_timepoints_data <- xy_merged_data %>%
  peekds::add_aois(.) %>%
  select(trial_id, administration_id, aoi, t, point_of_disambiguation) %>%
  peekds::rezero_times(.) %>%
  peekds::normalize_times(.) %>%
  peekds::resample_times(., table_type = "aoi_timepoints") %>%
  select(aoi_timepoint_id, trial_id, aoi, t_norm, administration_id) 

aoi_timepoints_data %>% 
  slice(1:5) %>%
  kable() %>% kable_styling()
```

That's it! Now, we'll write all the tables to `.csv` files and validate them to make sure they adhere to the schema. The osf write are commented out so you don't accidentally write a bunch of stuff when running this script. There you have it--that's how to import a Peekbank eyetracker dataset.

```{r write-all, message = FALSE, warning = FALSE}
output_path <- fs::path(project_root, "data", dataset_name, "processed_data")

# write_csv(df_dataset, file = here(output_path, "datasets.csv"))
# write_csv(subjects_data, file = here(output_path, "subjects.csv"))
# write_csv(stimuli_data, file = here(output_path,  "stimuli.csv"))
# write_csv(administration_data, file = here(output_path, "administrations.csv"))
# write_csv(trial_types_data, file = here(output_path, "trial_types.csv"))
# write_csv(trials_data, file = here(output_path, "trials.csv"))
# write_csv(aoi_region_sets, file = here(output_path, "aoi_region_sets.csv"))
# write_csv(xy_data, file = here(output_path, "xy_timepoints.csv"))
# write_csv(aoi_timepoints_data, file = here(output_path, "aoi_timepoints.csv"))

# run validation
# peekds::validate_for_db_import(dir_csv = output_path)

# OSF integration
# token <- read_lines(here("../token.txt"))[1] # please specific your own personal access token
# osf_token <- osf_auth(token = token) 
# put_processed_data(osf_token, dataset_name, paste0(output_path,"/"), osf_address = OSF_ADDRESS)
```

Finally, we'll create a simple visualization plot for this dataset.
```{r vis, message = FALSE, warning = FALSE}
aoi_timepoints_data %>%
  left_join(trials_data) %>%
  left_join(trial_types_data) %>%
  group_by(t_norm, condition) %>%
  filter(aoi %in% c("target", "distractor")) %>%
  summarise(correct = mean(aoi == "target")) %>%
  ggplot(aes(x = t_norm, y = correct, col = condition)) +
  geom_line() +
  xlim(-3000, 4000) +
  geom_hline(aes(yintercept = .5), lty = 2) +
  theme_bw()
```